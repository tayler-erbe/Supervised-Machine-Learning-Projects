{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa89a55-e4be-47e0-ab9c-e746803cdd75",
   "metadata": {},
   "source": [
    "# Niave Bayes:  Spam Filtering \n",
    "\n",
    "## INDEX\n",
    "- Bayes Theorem \n",
    "- Imports\n",
    "- Import Dataset CSV from Prpare Data\n",
    "- Update Fix Datframe \n",
    "    - Seperate Data Spam/Ham\n",
    "- Calculate Probabilities\n",
    "- Create Spam/Ham Dataframes Containing Word Frequency, Word Probabilities, Spam/Ham Probability\n",
    "- Hardcoded Calculation Using Naive Bayes to Classify Spam or Normal Message(\"Ham\")\n",
    "    - Psuedo Code for Naive Bayes Calculation \n",
    "    - Use pandas datframe to calculated the prior \n",
    "    - Test with Random Examples from Dataset \n",
    "    - Test with Real 'Ham' Email \n",
    "- References\n",
    "\n",
    "Using Naive Bayes to Classify Spam or Normal Message(\"Ham\")\n",
    "In this file I have hardcoded the calculation for classifying whether a message is a Normal Email or a Spam Email based on the probability that a list of tokenized words given word in each of the messages would be present. \n",
    "\n",
    "#### Previous Files in this Folder \n",
    "\n",
    "__Prepare_Data.ipynb :__\n",
    "Used to pre-process, clean and prepare the dataset used to test and train in this file. A csv was exported and read into this file. \n",
    "\n",
    "__EDA_Text_Data_Exploration :__\n",
    "Used to explore the most frequently used words, to look for commonalities and to help fine tune the prepare_data file so that i cleaned the words properly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290b29c-b97a-4847-97d3-9de2976548de",
   "metadata": {},
   "source": [
    "## Bayes Theorem & Naive Bayes Explained \n",
    "\n",
    "Probability of A given B \n",
    "\n",
    "    P ( A | B ) \n",
    "    \n",
    "The probability of A given B is the probability that A and B (the intersection) have happened divided by the probability that B has happened, that is:\n",
    "\n",
    "                      P ( A n B ) \n",
    "    P ( A | B )  =   -------------\n",
    "                        P ( B )\n",
    "                        \n",
    "Now, what about the probability that B has happened, given that A has also happened? Following the previous formula, we have that:\n",
    "\n",
    "                      P ( B n A ) \n",
    "    P ( B | A )  =   -------------\n",
    "                        P ( A )\n",
    "                     \n",
    "Notice from the Venn diagram that\n",
    "\n",
    "    P ( B n A ) == P ( A n B ) \n",
    "    \n",
    "Thus, by equating Eq. 1 and Eq. 2 we get the Bayes theorem:\n",
    "\n",
    "                    P ( B | A ) P ( A )\n",
    "    P ( A | B ) =  ---------------------\n",
    "                        P ( B )\n",
    "\n",
    "Given the significance of Bayes theorem in the theory of probability, each term has a name:\n",
    "\n",
    "                    likelihood x prior\n",
    "    posterior  =  -----------------------\n",
    "                        evidence \n",
    "                        \n",
    "In simple terms, the “prior” P(A) and the “evidence” P(B) refer to the probabilities of observing A and B independently from each other, whereas the “posterior” and the “likelihood” are the conditional probabilities of observing A given B and vice versa.\n",
    "\n",
    "                                        P ( Message_Word | Spam ) P ( Spam) \n",
    "            P ( Spam | Message_Word ) = ------------------------------------\n",
    "                                                    P ( Message_Word ) \n",
    "            \n",
    "\n",
    "            Message_word = { w1,w2,w3,...wi ) \n",
    "            \n",
    "Where Message_Word is a feature vector containing the words coming from the Spam (or Ham) emails\n",
    "\n",
    "\n",
    "The “Naive” assumption that the Naive Bayes classifier makes is that the probability of observing a word is independent of each other. The result is that the “likelihood” is the product of the individual probabilities of seeing each word in the set of Spam or Ham emails. We calculated these probabilities in Step 3 and stored them in the “occurrence” column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8cf72c7c-055f-4c2d-b83d-a7b5f4c3488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip uninstall scikit-learn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f5f627a3-d354-41be-a75f-826aad23cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8bfdd245-c277-478d-b578-197156b97435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation\n",
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import urllib\n",
    "\n",
    "#Sklearn\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613397da-ea4d-4a65-961d-3cb74f75cb27",
   "metadata": {},
   "source": [
    "### Import Data Set \n",
    "This dataset has been processed. See jupyter notebook file titled \"Prepare_Data\" for methods to process this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7bee807a-3d49-4ff1-b868-a0f1cc97df0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unknown</th>\n",
       "      <th>ham/spam</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>is_Spam</th>\n",
       "      <th>Word_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>['meter', 'follow', 'note', 'gave', 'prelimina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "      <td>['see', 'attached', 'file']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>['neon', 'retreat', 'around', 'wonderful', 'ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "      <td>['office', 'cheap', 'main', 'darer', 'prudentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>['deal', 'book', 'revenue', 'understanding', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unknown ham/spam                                      Original_Text  \\\n",
       "0      605      ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1     2349      ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2     3624      ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3     4685     spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4     2030      ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   is_Spam                                          Word_List  \n",
       "0        0  ['meter', 'follow', 'note', 'gave', 'prelimina...  \n",
       "1        0                        ['see', 'attached', 'file']  \n",
       "2        0  ['neon', 'retreat', 'around', 'wonderful', 'ti...  \n",
       "3        1  ['office', 'cheap', 'main', 'darer', 'prudentl...  \n",
       "4        0  ['deal', 'book', 'revenue', 'understanding', '...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spam_ham_processed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cb898a-62ef-49c1-8a37-812b854d291d",
   "metadata": {},
   "source": [
    "#### Update/Fix Dataframe\n",
    "When exporting the data from a dataframe to csv from the Prepare_Data file the column data for Word_List which was originally a list inside each column row is mistakenly turned into one long string. The following code fixes and updates the datafram to have a list of words again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "24acab08-3f9c-4278-9af3-08d228506cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processString(txt):\n",
    "    specialChars = \"[]',\"\n",
    "    for specialChar in specialChars:\n",
    "        txt = txt.replace(specialChar, '')\n",
    "    return txt.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ab727-04fa-48a3-a66f-69bc9c6598fb",
   "metadata": {},
   "source": [
    "##### Fix Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cca0494f-f215-4887-bbdd-d60182c35823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unknown</th>\n",
       "      <th>ham/spam</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>is_Spam</th>\n",
       "      <th>Word_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>[meter, follow, note, gave, preliminary, flow,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "      <td>[see, attached, file]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>[neon, retreat, around, wonderful, time, year,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[office, cheap, main, darer, prudently, fortui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[deal, book, revenue, understanding, u, check,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unknown ham/spam                                      Original_Text  \\\n",
       "0      605      ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1     2349      ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2     3624      ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3     4685     spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4     2030      ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   is_Spam                                          Word_List  \n",
       "0        0  [meter, follow, note, gave, preliminary, flow,...  \n",
       "1        0                              [see, attached, file]  \n",
       "2        0  [neon, retreat, around, wonderful, time, year,...  \n",
       "3        1  [office, cheap, main, darer, prudently, fortui...  \n",
       "4        0  [deal, book, revenue, understanding, u, check,...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix the Data Frame Column \"Word_List\" \n",
    "new_list = []\n",
    "for i in range(len(df)):\n",
    "    new_list.append(processString(df.Word_List[i]))\n",
    "    \n",
    "df[\"Word_List\"] = new_list\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eed1ad-d82a-463b-9139-3557cf107cf6",
   "metadata": {},
   "source": [
    "#### Seperate Data into Spam and Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "84ba7c8d-3aba-4290-bcb8-764d7c043dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the Data from ham and spam \n",
    "df_spam = df.loc[(df[\"ham/spam\"] == \"spam\")]\n",
    "df_spam = df_spam.reset_index()\n",
    "df_ham = df.loc[(df[\"ham/spam\"] == \"ham\")]\n",
    "df_ham = df_ham.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f182c75-a2d5-4fd5-9545-b746bee5d269",
   "metadata": {},
   "source": [
    "### Create New Dataframes \n",
    "#### Containing Word Frequency, Word Probabilities, Spam/Ham Probability\n",
    "Creating a datafram of the all the words and probability that the word is in the message\n",
    "\n",
    "__Columns__ \n",
    "- \"Word\" : Indicates which word we are calculating the probability for\n",
    "- \"Word_Frequency\" : The frequency in which the word occures in either spam or ham \n",
    "- \"Probability_Word_in_Spam\" : The probability that you would see the word in the message\n",
    "- \"Probability_is_Spam\" : The probability that the message is spam "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd0a9a-0ed5-4b08-ad26-3ad4259f6d72",
   "metadata": {},
   "source": [
    "#### Calculate Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a0a5cb62-f651-498a-88a3-10307bc133d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1/ len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67706016-e276-492c-8f85-de40f71f064c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Calculating the Probabilities of A Message Being Spam or Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1970cad4-5021-466a-9559-c4636a90d4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that the message IS NOT spam is 0.7101140978534133\n",
      "The probability that the message IS spam is 0.2898859021465867\n"
     ]
    }
   ],
   "source": [
    "# The probability a message is spam or ham \n",
    "p_ham = len(df_ham)/ len(df)\n",
    "p_spam = len(df_spam)/ len(df)\n",
    "\n",
    "print('The probability that the message IS NOT spam is ' + str(p_ham))\n",
    "print('The probability that the message IS spam is ' + str(p_spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790ccf8e-0a96-41f0-b910-f891ec039a92",
   "metadata": {},
   "source": [
    "#### Calculating the Probabilities of A Word is in a Message Spam or Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "26aa0284-acfc-4497-972f-75094af9d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of every word in all of the ham emails \n",
    "ham_list = []\n",
    "for i in range(len(df_ham['Word_List'])):\n",
    "    for j in range(len(df_ham['Word_List'][i])):\n",
    "        ham_list.append(df_ham['Word_List'][i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6a197a04-fb9d-414e-a0f0-65d554d40fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of every word in all of the ham emails \n",
    "spam_list = []\n",
    "for i in range(len(df_spam['Word_List'])):\n",
    "    for j in range(len(df_spam['Word_List'][i])):\n",
    "        spam_list.append(df_spam['Word_List'][i][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cfa77c37-bc1f-4ad9-90b7-b7d4adc0b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequency_df(list_of_words):\n",
    "    counter=collections.Counter(list_of_words)\n",
    "    word_frequency = list(counter.values())\n",
    "    word = list(counter.keys())\n",
    "    data_tuples = list(zip(word,word_frequency))\n",
    "    word_frequency = pd.DataFrame(data_tuples, columns=['Word','Word_Frequency'])\n",
    "    wf_df = word_frequency.copy()\n",
    "    wf_df = wf_df.sort_values('Word_Frequency', ascending=False)\n",
    "    return wf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea64111-5c48-4677-adac-3eea6c7bc057",
   "metadata": {},
   "source": [
    "#### Dataframes for Words, Word_Frequency, Probability_Word_in_Spam, Probability_is_Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "461c1fae-4a05-40ad-8418-e05a74f47bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word_Spam</th>\n",
       "      <th>Word_Frequency_Spam</th>\n",
       "      <th>Probability_Word_in_Spam</th>\n",
       "      <th>Probability_is_Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>company</td>\n",
       "      <td>728</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.289886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>information</td>\n",
       "      <td>517</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.289886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>font</td>\n",
       "      <td>515</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>0.289886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>please</td>\n",
       "      <td>483</td>\n",
       "      <td>0.004532</td>\n",
       "      <td>0.289886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>get</td>\n",
       "      <td>481</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.289886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word_Spam  Word_Frequency_Spam  Probability_Word_in_Spam  \\\n",
       "110       company                  728                  0.006832   \n",
       "140   information                  517                  0.004852   \n",
       "2936         font                  515                  0.004833   \n",
       "251        please                  483                  0.004532   \n",
       "293           get                  481                  0.004514   \n",
       "\n",
       "      Probability_is_Spam  \n",
       "110              0.289886  \n",
       "140              0.289886  \n",
       "2936             0.289886  \n",
       "251              0.289886  \n",
       "293              0.289886  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 most frequently used words in spam emails\n",
    "spam_wf = get_word_frequency_df(spam_list)\n",
    "spam_wf = spam_wf.rename(columns={'Word': 'Word_Spam', 'Word_Frequency': 'Word_Frequency_Spam'})\n",
    "\n",
    "# This adds to the frequency table the probability that each word is in a spam email \n",
    "spam_wf['Probability_Word_in_Spam'] = spam_wf.Word_Frequency_Spam / sum(spam_wf.Word_Frequency_Spam)\n",
    "spam_wf['Probability_is_Spam'] = len(df_spam)/ len(df)\n",
    "spam_wf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dc56db-05f1-4fb7-80fa-563ca4d4edee",
   "metadata": {},
   "source": [
    "#### Dataframes for Words, Word_Frequency, Probability_Word_in_Ham, Probability_is_Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a671a497-efbb-4b3a-ab42-57ab8f4bf7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word_Ham</th>\n",
       "      <th>Word_Frequency_Ham</th>\n",
       "      <th>Probability_Word_in_Ham</th>\n",
       "      <th>Probability_is_Ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gas</td>\n",
       "      <td>2856</td>\n",
       "      <td>0.017240</td>\n",
       "      <td>0.710114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>deal</td>\n",
       "      <td>2786</td>\n",
       "      <td>0.016818</td>\n",
       "      <td>0.710114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>subject</td>\n",
       "      <td>2731</td>\n",
       "      <td>0.016486</td>\n",
       "      <td>0.710114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>please</td>\n",
       "      <td>2715</td>\n",
       "      <td>0.016389</td>\n",
       "      <td>0.710114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meter</td>\n",
       "      <td>2452</td>\n",
       "      <td>0.014801</td>\n",
       "      <td>0.710114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word_Ham  Word_Frequency_Ham  Probability_Word_in_Ham  Probability_is_Ham\n",
       "18       gas                2856                 0.017240            0.710114\n",
       "143     deal                2786                 0.016818            0.710114\n",
       "248  subject                2731                 0.016486            0.710114\n",
       "8     please                2715                 0.016389            0.710114\n",
       "0      meter                2452                 0.014801            0.710114"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 most frequently used words in ham emails\n",
    "ham_wf = get_word_frequency_df(ham_list)\n",
    "ham_wf = ham_wf.rename(columns={'Word': 'Word_Ham', 'Word_Frequency': 'Word_Frequency_Ham'})\n",
    "# This adds to the frequency table the probability that each word is in a spam email \n",
    "ham_wf['Probability_Word_in_Ham'] = ham_wf.Word_Frequency_Ham / sum(ham_wf.Word_Frequency_Ham)\n",
    "ham_wf['Probability_is_Ham'] = len(df_ham)/ len(df)\n",
    "ham_wf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc805bfb-be51-4101-b70d-56a104a9b374",
   "metadata": {},
   "source": [
    "### Classifying Spam or Ham using Naive Bayes Probability Calculation\n",
    "Given a message we can look at the words in the message and see if given the words what is the probability that the message is spam or ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7beddce-2978-48f6-aab5-98d81eeadfcc",
   "metadata": {},
   "source": [
    "### Psuedo Code for Calculating Naive Bayes \n",
    "\n",
    "If we pick a random message from the original dataframe.\n",
    "\n",
    "__Prior Probability__\n",
    "    \n",
    "    Probability the Message is Ham \n",
    "    p_ham = num_ham_messages / total_num_messages\n",
    "    \n",
    "    Probability the Message is Spam \n",
    "    p_spam = num_spam_messages / total_num_messages\n",
    "\n",
    "__Probability Word is in Message Given that is is in Spam or Ham__\n",
    "\n",
    "    For Each Word in Random Message\n",
    "        if it is in spam, select the probability that it is a word in a spam message\n",
    "            p_spam * Probability_Word_in_Spam[i] (for each word in random message)\n",
    "            P( spam | random_message )\n",
    "            \n",
    "        if it is in ham, select the probability that it is a word in a ham message\n",
    "            p_ham * Probability_Word_in_Ham[i] (for each word in random message)\n",
    "        probabi\n",
    "            P( ham | random_message )\n",
    "        \n",
    "__Classify Based on Probability__ \n",
    "\n",
    "        if P( ham | random_message ) > P( spam | random_message )\n",
    "            then, ramdom_message == classify_as_ham\n",
    "            \n",
    "        if P( spam | random_message ) > P( ham | random_message ) \n",
    "            then, ramdom_message == classify_as_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "936cdb06-ce33-410b-89ec-4e91bf57cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the Probability Word is in Message Given that is is in Spam\n",
    "def probability_message_is_Spam(random_message):\n",
    "    p_spam_word_df = spam_wf.copy()\n",
    "    p_spam_word_df = p_spam_word_df.loc[spam_wf['Word_Spam'].isin(random_message)]\n",
    "    counter=collections.Counter(random_message)\n",
    "    count = list(counter.values())\n",
    "    word = list(counter.keys())\n",
    "    temp_df = pd.DataFrame(list(zip(word,count)), columns = ['Word_Spam','Word_Frequency_in_Message'])\n",
    "    merged_df = p_spam_word_df.merge(temp_df, on='Word_Spam', how='right', indicator=True)\n",
    "    merged_df['Probability_Word_in_Spam'] =merged_df['Probability_Word_in_Spam'].fillna(alpha)\n",
    "    merged_df['Update_Prob_Word_in_Spam'] = merged_df['Probability_Word_in_Spam']**merged_df['Word_Frequency_in_Message']\n",
    "    p_list_spam = list(merged_df['Update_Prob_Word_in_Spam'])\n",
    "    return np.prod(p_list_spam)*p_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d07c2887-a982-45d5-a56f-e21df586ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_message_is_Ham(random_message):\n",
    "    p_ham_word_df = ham_wf.copy()\n",
    "    p_ham_word_df = p_ham_word_df.loc[ham_wf['Word_Ham'].isin(random_message)]\n",
    "    counter=collections.Counter(random_message)\n",
    "    count = list(counter.values())\n",
    "    word = list(counter.keys())\n",
    "    temp_df = pd.DataFrame(list(zip(word,count)), columns = ['Word_Ham','Word_Frequency_in_Message'])\n",
    "    merged_df = p_ham_word_df.merge(temp_df, on='Word_Ham', how='right', indicator=True)\n",
    "    merged_df['Probability_Word_in_Ham'] =merged_df['Probability_Word_in_Ham'].fillna(alpha)\n",
    "    merged_df['Update_Prob_Word_in_Ham'] = merged_df['Probability_Word_in_Ham']**merged_df['Word_Frequency_in_Message']\n",
    "    p_list_ham = list(merged_df['Update_Prob_Word_in_Ham'])\n",
    "    return np.prod(p_list_ham)*p_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "82f86598-279e-48c8-9db3-df31288c43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify Based on Probability\n",
    "def classify_ham_or_spam(random_message, row_n):\n",
    "    is_Spam = df['is_Spam'][row_n]\n",
    "    \n",
    "    if probability_message_is_Ham(random_message) > probability_message_is_Spam(random_message):\n",
    "        is_classified = 0\n",
    "        correct_classification = is_classified == is_Spam\n",
    "        print(\"The message is ham, which is \" + str(correct_classification))\n",
    "    if probability_message_is_Spam(random_message) > probability_message_is_Ham(random_message):\n",
    "        is_classified = 1\n",
    "        correct_classification = is_classified == is_Spam\n",
    "        print(\"The message is spam, which is \" + str(correct_classification))\n",
    "    if probability_message_is_Spam(random_message) == 0.0:\n",
    "        print(\"This returned two small of a number to identify\") \n",
    "    if probability_message_is_Ham(random_message) == 0.0:\n",
    "        print(\"This returned two small of a number to identify\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08c0f47-a558-43b9-aa47-fb9291e7112f",
   "metadata": {},
   "source": [
    "#### Test with Random Examples from Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a1cb1b-d7f8-4cca-9159-c46d6d371946",
   "metadata": {},
   "source": [
    "This testing any randomly chosen message which already exists in the data set. Then calculates whether the probability is higher that it is spam or ham. After it classifies it, I compare to whether it was true or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f8370b6c-1d78-4992-9efa-d6b802f460ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The message is ham, which is True\n"
     ]
    }
   ],
   "source": [
    "# Generate a random list of pre-processed words from a message already present in dataset\n",
    "random_n = random.randint(1,len(df['Word_List']))\n",
    "random_message = df['Word_List'][random_n]\n",
    "\n",
    "#Classify Random Message as Spam or Ham \n",
    "classify_ham_or_spam(random_message,random_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239263d1-773f-4b14-aa7f-a72f36785d8f",
   "metadata": {},
   "source": [
    "__Explanation__\n",
    "\n",
    "Output: \n",
    "    \"The message is [Classified As Spam or Ham], \n",
    "    which is [Boolean dependent on whether Classified == Actual from Dataset]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9645e93-1a21-4807-a442-ceabe237888c",
   "metadata": {},
   "source": [
    "#### Test with Real \"Ham\" Email "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7312cf-6a85-419b-a904-01d170b991a2",
   "metadata": {},
   "source": [
    "For fun, I took a real email which WAS NOT Spam tested it in this model. I wanted to see if it  would classify the email as spam or not. This Naive Bayes classifier failed to detect that this was a real message and there are many reason for why that may be the case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bd9a748c-20c9-44c1-bc42-6d5ded0b35bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The message is spam, which is False\n"
     ]
    }
   ],
   "source": [
    "# Testing a real email that should be classified as ham, which I recieved from General Automics\n",
    "testing_real_ham = \"Thank you for your interest in a career opportunity with General Atomics.\"\n",
    "test_real_ham = testing_real_ham.split()\n",
    "classify_ham_or_spam(test_real_ham,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740da6e8-fe3a-4f17-9e7e-cc6760e7efc5",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "  __WEBLINKS__\n",
    "    Performing Sentiment Analysis With Naive Bayes Classifier!\n",
    "    https://www.analyticsvidhya.com/blog/2021/07/performing-sentiment-analysis-with-naive-bayes-classifier/\n",
    "    Naive Bayes Using SciKit-Learn\n",
    "    https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "  __VIDEOS__\n",
    "  - Naive Bayes Tutorial: \n",
    "      - https://www.youtube.com/watch?v=O2L2Uv9pdDA\n",
    "  - Text Classification Using Naive Bayes | Naive Bayes Algorithm In Machine Learning | Simplilearn :\n",
    "      - https://www.youtube.com/watch?v=60pqgfT5tZM\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
